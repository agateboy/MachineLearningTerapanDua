# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1atNjyyRoyCsXm3Zdyo7cavwR7J28DmCw

# Data Collection
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import mean_squared_error
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

!pip install kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d CooperUnion/anime-recommendations-database

!unzip anime-recommendations-database.zip

anime = pd.read_csv('anime.csv')
ratings = pd.read_csv('rating.csv')

"""# Data Understanding

## Data Anime
"""

anime.head(10)

anime.shape

anime.info()

anime.describe()

"""## Data Rating"""

ratings.head(10)

ratings.shape

ratings.info()

ratings.describe()

"""#Exploratory Data Analysis"""

import matplotlib.pyplot as plt
plt.figure(figsize=(8, 8))
anime['type'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)
plt.title('Distribution of Anime Types')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(anime['rating'].dropna(), bins=20, kde=True)
plt.title('Distribution of Anime Average Ratings')
plt.xlabel('Average Rating')
plt.ylabel('Number of Anime')
plt.show()

top_community_anime = anime.sort_values(by='members', ascending=False).head(10)
plt.figure(figsize=(12, 6))
sns.barplot(x='members', y='name', data=top_community_anime, palette='viridis')
plt.title('Top 10 Anime by Community Size')
plt.xlabel('Number of Members')
plt.ylabel('Anime Name')
plt.show()

top_rated_anime = anime.sort_values(by='rating', ascending=False).head(10)
plt.figure(figsize=(12, 6))
sns.barplot(x='rating', y='name', data=top_rated_anime, palette='magma')
plt.title('Top 10 Anime by Average Rating')
plt.xlabel('Average Rating')
plt.ylabel('Anime Name')
plt.xlim(top_rated_anime['rating'].min() * 0.95, top_rated_anime['rating'].max() * 1.05) # Adjust x-axis limits for better visualization
plt.show()

"""# Data Preparation"""

anime.isnull().sum()

anime.dropna(subset=['name'], inplace=True)

anime['genre'] = anime['genre'].fillna('')

anime.isna().sum()

ratings.isna().sum()

ratings = ratings[ratings['rating'] != -1]

ratings.head(10)

"""## TF-IDF Vectorization"""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(anime['genre'])

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

indices = pd.Series(anime.index, index=anime['name']).drop_duplicates()

"""# Model Development Content Based Filtering"""

def get_content_recommendations(title, top_n=10):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    anime_indices = [i[0] for i in sim_scores]
    return anime[['name', 'genre']].iloc[anime_indices]

print("\nContent-Based Top 10 Recommendations for 'Naruto':")
print(get_content_recommendations("Naruto"))

"""# Model Development Collaborative Filtering (User-Based)"""

user_anime_matrix = ratings.pivot_table(index='user_id', columns='anime_id', values='rating')

user_anime_matrix_filled = user_anime_matrix.fillna(0)

user_similarity = cosine_similarity(user_anime_matrix_filled)
user_sim_df = pd.DataFrame(user_similarity, index=user_anime_matrix.index, columns=user_anime_matrix.index)

def predict_rating(user_id, anime_id):
    if anime_id not in user_anime_matrix.columns:
        return np.nan
    sim_scores = user_sim_df[user_id]
    ratings_for_anime = user_anime_matrix[anime_id]
    valid = ratings_for_anime[ratings_for_anime.notna()]
    sim_scores = sim_scores[valid.index]
    if sim_scores.sum() == 0:
        return np.nan
    return np.dot(sim_scores, valid) / sim_scores.sum()

def get_top_n_recommendations(user_id, n=10):
    watched = ratings[ratings['user_id'] == user_id]['anime_id']
    anime_ids = user_anime_matrix.columns.difference(watched)
    predictions = [(anime_id, predict_rating(user_id, anime_id)) for anime_id in anime_ids]
    predictions = [p for p in predictions if not np.isnan(p[1])]
    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]
    anime_names = anime.set_index('anime_id').loc[[i[0] for i in top_n]]['name']
    return anime_names.reset_index(drop=True)

print("\nCollaborative Top 10 Recommendations for User 1:")
print(get_top_n_recommendations(1))

"""# Evaluation Metric"""

sample_ratings = ratings.sample(1000, random_state=1)
preds = []
actuals = []

for _, row in sample_ratings.iterrows():
    pred = predict_rating(row['user_id'], row['anime_id'])
    if not np.isnan(pred):
        preds.append(pred)
        actuals.append(row['rating'])

rmse = sqrt(mean_squared_error(actuals, preds))
print(f"\nRMSE for Collaborative Filtering on sample: {rmse:.4f}")